---
title: "`r (doc_title <- 'reticulate - Using R for Data Wrangling and Python for A Classification Task')`"
author: " Manuel Tilgner (author), E Bryan Crenshaw III (implemented here) "
date: "`r format(Sys.Date(), '%B %d, %Y')`"
output: 
  html_document:
    theme: spacelab
    highlight: default
    toc: TRUE
    toc_depth: 5
    toc_float: TRUE
---
<style>
div.blue { background-color:#e6f0ff; 
			border-radius: 5px; 
			padding: 8px 20px 8px 20px; 
			color: black}
table caption {font-weight: bold;
               color: #444;
               font-size: 1.5em;}
</style>
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
# In AudGenDB, the default organization is for .Rmd files to reside in the 'rmarkdown' subfolder
# The following command finds the project directory it no matter where the Rmd file is located 
# knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())

# Note: To get the plt.show() to work in the last python chunk, the above opts_knit() statement routinely used by the AudGenDB template had to be commented out. When this occurred, the paths of the data input had to be changed, because the rmarkdown folder was the working directory, instead of the rootdir (as specified above).
```

### Objective ### 
Introductory exercise in which R is used for data preprocessing, and Python is used in `reticulate` to train a Support Vector Machine for a simple classification task.  

### Introduction
This is a worked example of the tutorial, [R and Python: Using reticulate to get the best of both worlds](https://www.statworx.com/de/blog/r-and-python-using-reticulate-to-get-the-best-of-both-worlds/). Although only a year old at the time this example was rerun, there have been numerous changes that needed to be addressed to get the example to run without error or warnings. These changes were outlined in the Conclusion section at the end of this R Markdown report. The text in the "Data Analysis" section and the first part of the "Conclusions" is from the original post. Tweeks made to the code are flagged with comment (### Updated script), and summarized at end of Conclusions.  

### Approach ### 
Follow instructions in [R and Python: Using reticulate to get the best of both worlds](https://www.statworx.com/de/blog/r-and-python-using-reticulate-to-get-the-best-of-both-worlds/). Several issues were addressed, as outlined in the Conclusions section.

```{r LoadLibraries}
#Load libraries in this first chunk
library(tidyverse)
library(recipes)
library(reticulate)

# Setup python environment using conda
use_condaenv("/anaconda3/bin/python3")
py_config()

# Load external R scripts here
# How to embed in R Markdown: < https://yihui.name/knitr/demo/externalization/ >
knitr::read_chunk('../scripts/yaml_metadata.R')
```

```{r LoadData, cache=FALSE}
#Load data in this chunk

#### Input File Names
input_file      <- "../data/Dispatchers_Background_Data.xls"
metadata_yml    <- '../data/Dispatchers_Background_Data.yml'

### Data Input
data <- readxl::read_xls(input_file)
 
```

### Input Metadata

```{r yaml_metadata, echo=FALSE}

```

### Data Analysis ### 

#### Data Transformation in `dplyr`

Let’s read perform some transformations with dplyr. This is mostly recoding work. As you can see in the select command, we pick a handful of variables like sex, age, caffeine consumption, health and stress to predict whether a railroad dispatcher was diagnosed with a sleeping disorder.

```{r PreprocessingData}
# Data Processing
sleep <- data %>%
  select(
      Diagnosed_Sleep_disorder, Age_Group, Sex, Total_years_dispatcher,
      Total_years_present_job, Marital_Status, Childrendependents,
      Children_under_2_yrs, Caff_Beverages, Sick_Days_in_last_year,
      Health_status, Avg_Work_Hrs_Week, FRA_report, Phys_Drained,
      Mentally_Drained, Alert_at_Work, Job_Security
  ) %>%
  rename_all(tolower) %>%
  mutate_if(is.character, as.numeric) %>%
  mutate_at(vars(diagnosed_sleep_disorder, sex, caff_beverages, fra_report),
            ~ -(. - 2)) %>%
  mutate_at(vars(marital_status), ~ (. - 1)) %>%
  drop_na()
```

#### Prepare the Data

Now that we have the variables we want, it’s time to get the data into the right shape. Here’s one more reason to love `R`: the `recipes` package. If you’re not familiar with it, check it out. You may find its workflow a bit peculiar at first, but once you get used to it, it makes data preparation a breeze.

What we’re doing here is straightforward. First, we split the data into a training and test set. Next, we specify a data preparation recipe, which consists of three steps: one hot encoding factor predictors, standardising numeric predictors and down-sampling the data. One hot encoding and standardising ensure that the Support Vector Machine algorithm works properly. Down-sampling is a counter-measure against the class imbalance in our dataset.

```{r PrepareData}
numeric_variables <- c(
  "total_years_dispatcher", "total_years_present_job",
  "childrendependents", "children_under_2_yrs", 
  "sick_days_in_last_year", "avg_work_hrs_week"
)

factor_variables <- setdiff(colnames(sleep), numeric_variables)

sleep <- mutate_at(sleep, vars(factor_variables), as.factor)

set.seed(2019)
index <- sample(1:nrow(sleep), floor(nrow(sleep) * .75))

sleep_train <- sleep[index, ]
sleep_test <- sleep[-index, ]

recipe_formula <- recipes::recipe(diagnosed_sleep_disorder ~ ., sleep_train)

recipe_steps <- recipe_formula %>%
  recipes::step_dummy(factor_variables, -all_outcomes(), one_hot = TRUE) %>%
  recipes::step_downsample(diagnosed_sleep_disorder) %>%
  recipes::step_center(numeric_variables) %>%
  recipes::step_scale(numeric_variables)

recipe_prep <- recipes::prep(recipe_steps, sleep_train, retain = TRUE)

training_data <- juice(recipe_prep)
testing_data <- bake(recipe_prep, sleep_test)
```

#### Machine Learning in Python

Now comes the part where Python shines: its unified ML library scikit-learn. Let’s go ahead and import the Support Vector Machine (SVM) classifier as well as some other modules to tune and evaluate our model.

SVM is a supervised learning algorithm. It works by finding a hyperplane in an N-dimensional space, which separates two (or more) classes as cleanly as possible. More technically, SVM maximizes the margin or the distance between the separating hyperplane and the closest data points. This is why SVM is also called a maximum margin estimator.

SVM is mostly used for classification, but it can do regression too. The upside is that it works with high-dimensional data and different kernel functions, meaning it can flexibly adapt to different types of data. Its downside is that computation becomes costly with large datasets and that it reacts sensitively to hyperparameters. Still, for some applications SVM performs quite competitively.

Combining SVM with kernels allows us to project our data into a higher-dimensional space. The point of this is to make the classes better separable. In our example here, we’ll use a simple linear and a radial basis function kernel. The latter can map the predictor space into infinite dimensions.

```{python}
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

from sklearn import svm
from sklearn.model_selection import GridSearchCV, cross_val_score 
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score

### Updated script
y_train = np.array(r.training_data['diagnosed_sleep_disorder'])
X_train = np.array(r.training_data.drop('diagnosed_sleep_disorder', axis = 1))

y_test = np.array(r.testing_data['diagnosed_sleep_disorder'])
X_test = np.array(r.testing_data.drop('diagnosed_sleep_disorder', axis = 1))
###^^^----Updated script

clf = svm.SVC(kernel = 'linear', gamma='scale')
clf.fit(X_train, y_train)
y_pred = clf.predict(X_test)

print(confusion_matrix(y_test, y_pred))
print(classification_report(y_test, y_pred))

### Updated script
clf = svm.SVC(kernel = 'rbf', gamma='scale') # was originally 'RBF'
clf.fit(X_train, y_train)
y_pred = clf.predict(X_test)

print(confusion_matrix(y_test, y_pred))
print(classification_report(y_test, y_pred))

```

#### Tune the Model

```{python}
### Updated script
param_grid = [{'C': [0.01, 0.1, 1, 10, 100],
               'gamma': [0.001, 0.01, 0.1, 1, 10],
               'kernel': ['rbf', 'linear']}] # RBF

### Updated script
grid = GridSearchCV(svm.SVC(), param_grid, cv = 5, scoring = 'balanced_accuracy', iid=True)

grid.fit(X_train, y_train)

print(grid.best_params_)

```

#### Evaluate the Accuracy of the Model

```{python}
lf = grid.best_estimator_
y_pred = clf.predict(X_test)

print('Confusion Matrix:\n\n', confusion_matrix(y_test, y_pred))
print('\nClassification Report:\n\n', classification_report(y_test, y_pred))
print('\nTraining Set Accuracy: {:.2f}%'.format(clf.score(X_train, y_train)))
print('\nTest Set Accuracy: {:.2f}%'.format(clf.score(X_test, y_test)))

```

```{python}
# This chunk has been left unevaluated, because RMarkdown can't find the .png output
conf_mat = confusion_matrix(y_test, y_pred)

sns.heatmap(conf_mat, square = True, annot = True, fmt = 'g',
            cbar = False, cmap = 'viridis')
plt.xlabel('predicted')
plt.ylabel('observed')
plt.show()
```

### Conclusion ###   
<div class = "blue">
#### Original Conclusions
In this case, we achieve a training set accuracy of 93 per cent and a test set accuracy of 74 per cent. This suggests that some overfitting has occurred. To achieve a higher accuracy (or better: sensitivity/recall), we could experiment with different kernels and/or hyperparameter values. But this I’d leave up to you. With reticulate, you now have a tool to get the best of both `R` and `Python`.

#### Updates Needed
Several tweeks were made to this tutorial to get it to run without errors or warnings:  
- The test and training data needed to be explicitly converted to np.array (e.g., y_train = np.array(...)) to avoid an error.  
- 'RBF' had to be changed to 'rbf' to avoid an error, and `gamma` needed to made explicit to address warnings (e.g, `svm.SVC(kernel = 'rbf', gamma='scale')`).  
- To the `grid` assignment in "Tune the model," `, iid=True` had to be added to address warnings about changes in the versions.   
</div>

<br /><br />
<details>
<summary>Click here for session info.</summary>

```{r SessionInfo}
# This session info field shows the environment when the R script was run
# It will be hidden in documents, except for the summary above and a triangle
# Clicking on the triangle/summary statement will reveal these data in the browser
sessionInfo()
py_config()
print(paste0("This R Markdown Document was run on ",format(Sys.Date(),"%d-%b-%Y")))

# If the user in not inside RStudio, then this will send a notification to the OS 
# NOTE: Notifier was not on CRAN in March 2019
# To get package: 
#install.packages("devtools") if devtools is not installed
#devtools::install_github("gaborcsardi/notifier")
################################################
require(notifier)
msg <- paste0(doc_title, " is done!")
notifier::notify(msg, title = "R notification", image = NULL)
```

</details>
<br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br />